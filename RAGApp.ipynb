{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9cde2246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "import os\n",
    "from typing import List, Any\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "540635d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH=r\"C:\\Users\\andia\\OneDrive\\Desktop\\EXAM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2fa8f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 14 pages from 2 PDFs\n"
     ]
    }
   ],
   "source": [
    "#Loading a Document \n",
    "#loader=PyPDFLoader(r\"C:\\Users\\andia\\OneDrive\\Desktop\\EXAM\\RAG_and_HR_Policies_FAQs.pdf\")\n",
    "#document=loader.load()\n",
    "\n",
    "pdf_files = [f for f in os.listdir(DATA_PATH) if f.endswith(\".pdf\")]\n",
    "\n",
    "document = []\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    file_path = os.path.join(DATA_PATH, pdf_file)\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    document.extend(documents)  # accumulate all pages from all PDFs\n",
    "\n",
    "print(f\"Loaded {len(document)} pages from {len(pdf_files)} PDFs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b059ce82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load all the pdf files from the directory\n",
    "dir_loader=DirectoryLoader(\n",
    "    DATA_PATH,\n",
    "    glob=\"**/*.pdf\", ## Pattern to match files  \n",
    "    loader_cls= PyMuPDFLoader, ##loader class to use\n",
    "    show_progress=False\n",
    "\n",
    ")\n",
    "\n",
    "pdf_documents=dir_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aab85dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#READING THE PDF\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(DATA_PATH)\n",
    "    \n",
    "    # Find all PDF files recursively\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "    \n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nProcessing: {pdf_file.name}\")\n",
    "        try:\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "            \n",
    "            # Add source information to metadata\n",
    "            for doc in documents:\n",
    "                doc.metadata['source_file'] = pdf_file.name\n",
    "                doc.metadata['file_type'] = 'pdf'\n",
    "            \n",
    "            all_documents.extend(documents)\n",
    "            print(f\"  ✓ Loaded {len(documents)} pages\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error: {e}\")\n",
    "    \n",
    "    print(f\"\\nTotal documents loaded: {len(all_documents)}\")\n",
    "    return all_documents\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ac0155c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 PDF files to process\n",
      "\n",
      "Processing: DecisionTrees.pdf\n",
      "  ✓ Loaded 11 pages\n",
      "\n",
      "Processing: RAG_and_HR_Policies_FAQs.pdf\n",
      "  ✓ Loaded 3 pages\n",
      "\n",
      "Total documents loaded: 14\n"
     ]
    }
   ],
   "source": [
    "# Process all PDFs in the data directory\n",
    "all_pdf_documents = process_all_pdfs(\"DATA_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "892f5f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHUNKING AND SPLITTING DATA\n",
    "def split_documents(documents,chunk_size=2000,chunk_overlap=100):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "    \n",
    "    \n",
    "    return split_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3740496e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 14 documents into 17 chunks\n"
     ]
    }
   ],
   "source": [
    "chunks=split_documents(all_pdf_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b8646eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DUMMY EMBEDDING CLASS\n",
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embedding generation using TF-IDF.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            max_features=2048,\n",
    "            stop_words=\"english\"\n",
    "        )\n",
    "        self.fitted = False\n",
    "        print(\"TF-IDF Embedding Manager Initialized\")\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        if not self.fitted:\n",
    "            print(\"Fitting TF-IDF vectorizer...\")\n",
    "            self.vectorizer.fit(texts)\n",
    "            self.fitted = True\n",
    "        embeddings = self.vectorizer.transform(texts).toarray()\n",
    "        print(f\"Generated embeddings: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "\n",
    "    def embed_query(self, query: str) -> np.ndarray:\n",
    "        if not self.fitted:\n",
    "            raise RuntimeError(\"Vectorizer not fitted yet!\")\n",
    "        return self.vectorizer.transform([query]).toarray()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14ff2d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Embedding Manager Initialized\n"
     ]
    }
   ],
   "source": [
    "embedding_manager = EmbeddingManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2aa8876f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TF-IDF vectorizer...\n",
      "Generated embeddings: (17, 1017)\n"
     ]
    }
   ],
   "source": [
    "texts = [doc.page_content for doc in chunks]\n",
    "embeddings = embedding_manager.generate_embeddings(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c937797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DUMMY VECTOR STORE #for decision trees.pdf this worked\n",
    "class VectorStore:\n",
    "    def __init__(self, collection_name=\"pdf_documents\", persist_directory=\"./vector_store\"):\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        os.makedirs(self.persist_directory, exist_ok=True)\n",
    "        self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "        self.collection = self.client.get_or_create_collection(\n",
    "        name=self.collection_name,\n",
    "        metadata={\"description\": \"PDF document embeddings for RAG\",\n",
    "              \"hnsw:space\": \"cosine\"}  # specify cosine distance metric here\n",
    "\n",
    "        )\n",
    "        print(f\"✅ Chroma collection '{self.collection_name}' ready\")\n",
    "        print(f\"Existing documents: {self.collection.count()}\")\n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Mismatch: documents and embeddings count\")\n",
    "\n",
    "        ids, metadatas, contents, vectors = [], [], [], []\n",
    "        for i, (doc, emb) in enumerate(zip(documents, embeddings)):\n",
    "            ids.append(f\"doc_{uuid.uuid4().hex[:8]}\")\n",
    "            metadatas.append(doc.metadata)\n",
    "            contents.append(doc.page_content)\n",
    "            vectors.append(emb.tolist())\n",
    "\n",
    "        self.collection.add(\n",
    "            ids=ids,\n",
    "            embeddings=vectors,\n",
    "            metadatas=metadatas,\n",
    "            documents=contents\n",
    "        )\n",
    "        print(f\"Added {len(documents)} docs to Chroma\")\n",
    "        print(f\"Total in collection: {self.collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cfc5d2ad-39ac-449d-9e4a-c5a338038b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for faqs\n",
    "# DUMMY VECTOR STORE\n",
    "import os\n",
    "import uuid\n",
    "import numpy as np\n",
    "import chromadb\n",
    "from typing import List, Any\n",
    "from chromadb.errors import InvalidDimensionException\n",
    "\n",
    "class VectorStore:\n",
    "    def __init__(self, collection_name=\"pdf_documents\", persist_directory=\"./vector_store\"):\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        os.makedirs(self.persist_directory, exist_ok=True)\n",
    "        self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "        self.collection = self.client.get_or_create_collection(\n",
    "            name=self.collection_name,\n",
    "            metadata={\n",
    "                \"description\": \"PDF document embeddings for RAG\",\n",
    "                \"hnsw:space\": \"cosine\"  # specify cosine distance metric here\n",
    "            }\n",
    "        )\n",
    "        print(f\"Chroma collection '{self.collection_name}' ready\")\n",
    "        print(f\"Existing documents: {self.collection.count()}\")\n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Mismatch: documents and embeddings count\")\n",
    "\n",
    "        ids, metadatas, contents, vectors = [], [], [], []\n",
    "        for i, (doc, emb) in enumerate(zip(documents, embeddings)):\n",
    "            ids.append(f\"doc_{uuid.uuid4().hex[:8]}\")\n",
    "            metadatas.append(doc.metadata)\n",
    "            contents.append(doc.page_content)\n",
    "            vectors.append(emb.tolist())\n",
    "\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=vectors,\n",
    "                metadatas=metadatas,\n",
    "                documents=contents\n",
    "            )\n",
    "            print(f\"Added {len(documents)} docs to Chroma\")\n",
    "            print(f\"Total in collection: {self.collection.count()}\")\n",
    "\n",
    "        except InvalidDimensionException as e:\n",
    "            print(\"Embedding dimension mismatch detected!\")\n",
    "            print(\"Resetting the collection to match the new embedding size...\")\n",
    "\n",
    "            # delete and recreate the collection\n",
    "            self.client.delete_collection(self.collection_name)\n",
    "            self.collection = self.client.create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\n",
    "                    \"description\": \"PDF document embeddings for RAG (reset after dimension mismatch)\",\n",
    "                    \"hnsw:space\": \"cosine\"\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # retry adding documents\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=vectors,\n",
    "                metadatas=metadatas,\n",
    "                documents=contents\n",
    "            )\n",
    "            print(f\"Collection reset and {len(documents)} docs added successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "06a5db0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma collection 'pdf_documents' ready\n",
      "Existing documents: 68\n",
      "Added 17 docs to Chroma\n",
      "Total in collection: 85\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Add the same chunked documents and their embeddings\n",
    "vector_store = VectorStore()\n",
    "vector_store.add_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "274f413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DUMMY RETRIEVER CLASS\n",
    "class RAGRetriever:\n",
    "    def __init__(self, vector_store: VectorStore, embedding_manager: EmbeddingManager):\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self, query: str, top_k: int = 5, score_threshold: float = 0.0):\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        query_emb = self.embedding_manager.embed_query(query)\n",
    "\n",
    "        results = self.vector_store.collection.query(\n",
    "            query_embeddings=[query_emb.tolist()],\n",
    "            n_results=top_k\n",
    "        )\n",
    "\n",
    "        retrieved_docs = []\n",
    "        if results and results.get(\"documents\") and results[\"documents\"][0]:\n",
    "            docs = results[\"documents\"][0]\n",
    "            metas = results[\"metadatas\"][0]\n",
    "            dists = results[\"distances\"][0]\n",
    "            ids = results[\"ids\"][0]\n",
    "\n",
    "            for i, (doc_id, text, meta, dist) in enumerate(zip(ids, docs, metas, dists)):\n",
    "                score = 1 - dist\n",
    "                if score >= score_threshold:\n",
    "                    retrieved_docs.append({\n",
    "                        \"id\": doc_id,\n",
    "                        \"content\": text,\n",
    "                        \"metadata\": meta,\n",
    "                        \"similarity_score\": score,\n",
    "                        \"rank\": i + 1\n",
    "                    })\n",
    "            print(f\"Retrieved {len(retrieved_docs)} documents\")\n",
    "        else:\n",
    "            print(\"No documents found\")\n",
    "\n",
    "        return retrieved_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18c5cd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_retriever=RAGRetriever(vector_store,embedding_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "29890c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: what is Leave Policy?\n",
      "Retrieved 3 documents\n",
      "\n",
      "Rank 1:\n",
      "Score: 0.375\n",
      "Content snippet: - Regularly re-embed when documents are updated.\n",
      "**FAQs:**\n",
      "Q1: Why does RAG sometimes return irrelevant context?\n",
      "A1: Chunking or embedding mismatch can cause poor retrieval. Recheck embeddings and\n",
      "retriever logic.\n",
      "Q2: Can I use local LLMs like Ollama...\n",
      "\n",
      "Rank 2:\n",
      "Score: 0.375\n",
      "Content snippet: - Regularly re-embed when documents are updated.\n",
      "**FAQs:**\n",
      "Q1: Why does RAG sometimes return irrelevant context?\n",
      "A1: Chunking or embedding mismatch can cause poor retrieval. Recheck embeddings and\n",
      "retriever logic.\n",
      "Q2: Can I use local LLMs like Ollama...\n",
      "\n",
      "Rank 3:\n",
      "Score: 0.375\n",
      "Content snippet: - Regularly re-embed when documents are updated.\n",
      "**FAQs:**\n",
      "Q1: Why does RAG sometimes return irrelevant context?\n",
      "A1: Chunking or embedding mismatch can cause poor retrieval. Recheck embeddings and\n",
      "retriever logic.\n",
      "Q2: Can I use local LLMs like Ollama...\n"
     ]
    }
   ],
   "source": [
    "#exmaple retrieval\n",
    "rag_retriever = RAGRetriever(vector_store, embedding_manager)\n",
    "results = rag_retriever.retrieve(\"what is Leave Policy?\", top_k=3)\n",
    "for r in results:\n",
    "    print(f\"\\nRank {r['rank']}:\")\n",
    "    print(f\"Score: {r['similarity_score']:.3f}\")\n",
    "    print(f\"Content snippet: {r['content'][:250]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ba6211a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"Please set your OPENAI_API_KEY in the environment variables (.env file)\")\n",
    "\n",
    "class OpenAILLM:\n",
    "    def __init__(self, model_name: str = \"gpt-3.5-turbo\", api_key: str = None):\n",
    "        \"\"\"\n",
    "        Initialize OpenAI LLM\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.api_key = api_key or OPENAI_API_KEY\n",
    "        \n",
    "        self.llm = ChatOpenAI(\n",
    "            model=model_name,        # new param name is `model` not `model_name`\n",
    "            temperature=0.1,\n",
    "            api_key=self.api_key,    # new param name is `api_key`\n",
    "            max_tokens=1024\n",
    "        )\n",
    "        \n",
    "        print(f\"Initialized OpenAI LLM with model: {self.model_name}\")\n",
    "\n",
    "    def generate_response(self, query: str, context: str, max_length: int = 500) -> str:\n",
    "        \"\"\"\n",
    "        Generate response using retrieved context\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"\n",
    "You are a helpful AI assistant. Use the following context to answer the question accurately and concisely.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "        try:\n",
    "            messages = [HumanMessage(content=prompt)]\n",
    "            response = self.llm.invoke(messages)  # use .invoke() instead of calling directly\n",
    "            return response.content\n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {str(e)}\"\n",
    "\n",
    "    def generate_response_simple(self, query: str, context: str) -> str:\n",
    "        \"\"\"\n",
    "        Simple response generation without complex prompting\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"Based on this context: {context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "        try:\n",
    "            messages = [HumanMessage(content=prompt)]\n",
    "            response = self.llm.invoke(messages)\n",
    "            return response.content\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dbda9408-bb9c-4575-8471-9bd12216d4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "    openai_api_key=\"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\",\n",
    ")\n",
    "\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "def rag_simple(query, retriever, llm, top_k=3):\n",
    "    \"\"\"Retrieve top-k context and generate a concise answer using ChatOpenAI\"\"\"\n",
    "\n",
    "    # Retrieve relevant documents\n",
    "    results = retriever.retrieve(query, top_k=top_k)\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in results]) if results else \"\"\n",
    "\n",
    "    if not context:\n",
    "        return \"No relevant context found to answer the question.\"\n",
    "\n",
    "    # Build the prompt\n",
    "    prompt = f\"\"\"Use the following context to answer the question exactly as given in context for educational purpose. If the context has no answers say I don't know\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "    # Print retrieved context\n",
    "    print(\"Context retrieved:\\n\", context)\n",
    "\n",
    "    # Call the LLM directly with messages\n",
    "    response = llm(\n",
    "        messages=[\n",
    "            SystemMessage(content=\"You are a helpful assistant that answers questions concisely using provided context.\"),\n",
    "            HumanMessage(content=prompt),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Return the answer text\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2617abb7-c318-4a22-9f86-66ac5fc1d8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: explain random forests and who introduced in which year?\n",
      "Retrieved 3 documents\n",
      "Context retrieved:\n",
      " 1-9\n",
      "3 Random Forests\n",
      "Random Forests is a popular technique to solve classification and regression problems and was introduced\n",
      "by Breiman [2001]. It builds on a combination of tree predictors (ensemble method) that operates by\n",
      "constructing a multitude of trees during the training phase and asking each tree to output the mode of the\n",
      "classes (most popular class in classification) or mean predictions (in regression). Then we pick the majority\n",
      "(classification) or mean (regression) across trees to make predictions. From a mathematical standpoint, we\n",
      "can interpret the function approximation of random forests as follows:\n",
      "f(x) =\n",
      "BX\n",
      "t=1\n",
      "ft(x)\n",
      "B ,\n",
      "where B is the number of trees in the ensemble, and eachft(x) is a CART that trains on a subset of\n",
      "the data that is chosen randomly with replacement (this is known asbootstrapping). Bagging (bootstrap\n",
      "aggregation) uses the aboveB bootstrap samples and averages the output (for regression) or takes majority\n",
      "(for classification). One of the challenges with this approach is that, if we use the same algorithm, then the\n",
      "predictor variables chosen will be highly correlated. This can be improved by learning trees on randomly\n",
      "chosen subsets of input variables. Note that RF provide less interpretability but often better predictive power\n",
      "than CART. Naturally, the larger the number of trees the larger the time needed to build the ensemble (a\n",
      "similar concept applies to the node sizes; smaller the node size, the larger the time needed to build the\n",
      "ensemble).\n",
      "In a typical implementation, a random sample of m ≈ √p predictors (for classification) and m ≈ p/3\n",
      "predictors (for regression) are considered at each split of the tree and the split is made based only on one of\n",
      "this candidate variables. This helps decorrelate the trees chosen by the Random Forest method and reduces\n",
      "the variance.\n",
      "(Rough) algorithm for Random Forests.For a selected number of treesB:\n",
      "• Sample observations (with replacement) to create a subset of data;\n",
      "\n",
      "1-9\n",
      "3 Random Forests\n",
      "Random Forests is a popular technique to solve classification and regression problems and was introduced\n",
      "by Breiman [2001]. It builds on a combination of tree predictors (ensemble method) that operates by\n",
      "constructing a multitude of trees during the training phase and asking each tree to output the mode of the\n",
      "classes (most popular class in classification) or mean predictions (in regression). Then we pick the majority\n",
      "(classification) or mean (regression) across trees to make predictions. From a mathematical standpoint, we\n",
      "can interpret the function approximation of random forests as follows:\n",
      "f(x) =\n",
      "BX\n",
      "t=1\n",
      "ft(x)\n",
      "B ,\n",
      "where B is the number of trees in the ensemble, and eachft(x) is a CART that trains on a subset of\n",
      "the data that is chosen randomly with replacement (this is known asbootstrapping). Bagging (bootstrap\n",
      "aggregation) uses the aboveB bootstrap samples and averages the output (for regression) or takes majority\n",
      "(for classification). One of the challenges with this approach is that, if we use the same algorithm, then the\n",
      "predictor variables chosen will be highly correlated. This can be improved by learning trees on randomly\n",
      "chosen subsets of input variables. Note that RF provide less interpretability but often better predictive power\n",
      "than CART. Naturally, the larger the number of trees the larger the time needed to build the ensemble (a\n",
      "similar concept applies to the node sizes; smaller the node size, the larger the time needed to build the\n",
      "ensemble).\n",
      "In a typical implementation, a random sample of m ≈ √p predictors (for classification) and m ≈ p/3\n",
      "predictors (for regression) are considered at each split of the tree and the split is made based only on one of\n",
      "this candidate variables. This helps decorrelate the trees chosen by the Random Forest method and reduces\n",
      "the variance.\n",
      "(Rough) algorithm for Random Forests.For a selected number of treesB:\n",
      "• Sample observations (with replacement) to create a subset of data;\n",
      "\n",
      "1-9\n",
      "3 Random Forests\n",
      "Random Forests is a popular technique to solve classification and regression problems and was introduced\n",
      "by Breiman [2001]. It builds on a combination of tree predictors (ensemble method) that operates by\n",
      "constructing a multitude of trees during the training phase and asking each tree to output the mode of the\n",
      "classes (most popular class in classification) or mean predictions (in regression). Then we pick the majority\n",
      "(classification) or mean (regression) across trees to make predictions. From a mathematical standpoint, we\n",
      "can interpret the function approximation of random forests as follows:\n",
      "f(x) =\n",
      "BX\n",
      "t=1\n",
      "ft(x)\n",
      "B ,\n",
      "where B is the number of trees in the ensemble, and eachft(x) is a CART that trains on a subset of\n",
      "the data that is chosen randomly with replacement (this is known asbootstrapping). Bagging (bootstrap\n",
      "aggregation) uses the aboveB bootstrap samples and averages the output (for regression) or takes majority\n",
      "(for classification). One of the challenges with this approach is that, if we use the same algorithm, then the\n",
      "predictor variables chosen will be highly correlated. This can be improved by learning trees on randomly\n",
      "chosen subsets of input variables. Note that RF provide less interpretability but often better predictive power\n",
      "than CART. Naturally, the larger the number of trees the larger the time needed to build the ensemble (a\n",
      "similar concept applies to the node sizes; smaller the node size, the larger the time needed to build the\n",
      "ensemble).\n",
      "In a typical implementation, a random sample of m ≈ √p predictors (for classification) and m ≈ p/3\n",
      "predictors (for regression) are considered at each split of the tree and the split is made based only on one of\n",
      "this candidate variables. This helps decorrelate the trees chosen by the Random Forest method and reduces\n",
      "the variance.\n",
      "(Rough) algorithm for Random Forests.For a selected number of treesB:\n",
      "• Sample observations (with replacement) to create a subset of data;\n",
      "Answer is\n",
      "\n",
      "\n",
      "Random Forests is a popular technique to solve classification and regression problems and was introduced by Breiman in 2001. It builds on a combination of tree predictors (ensemble method) that operates by constructing a multitude of trees during the training phase and asking each tree to output the mode of the classes (most popular class in classification) or mean predictions (in regression). Then we pick the majority (classification) or mean (regression) across trees to make predictions.\n"
     ]
    }
   ],
   "source": [
    "answer=rag_simple(\"explain random forests and who introduced in which year?\",rag_retriever,llm)\n",
    "print(\"Answer is\\n\\n\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2207db67-3b7a-49d7-926b-61eb98580e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: what is the Leave policy?\n",
      "Retrieved 3 documents\n",
      "Context retrieved:\n",
      " - Regularly re-embed when documents are updated.\n",
      "**FAQs:**\n",
      "Q1: Why does RAG sometimes return irrelevant context?\n",
      "A1: Chunking or embedding mismatch can cause poor retrieval. Recheck embeddings and\n",
      "retriever logic.\n",
      "Q2: Can I use local LLMs like Ollama or Llama 3?\n",
      "A2: Yes, with LangChain or LlamaIndex integration using `OllamaLLM` or API endpoints.\n",
      "Q3: What’s the difference between RAG and fine-tuning?\n",
      "A3: RAG retrieves knowledge dynamically; fine-tuning embeds it permanently into the\n",
      "model.\n",
      "Q4: How to improve accuracy?\n",
      "A4: Use domain-specific embeddings, better retriever ranking, or hybrid (keyword +\n",
      "semantic) search.\n",
      "Section 2: HR Policies and Employee FAQs\n",
      "**1. Leave Policy**\n",
      "- Employees are entitled to annual leave, sick leave, and public holidays as per labor law.\n",
      "- All leave must be approved by reporting managers.\n",
      "- Emergency leave must be informed at the earliest.\n",
      "**2. Attendance & Working Hours**\n",
      "- Standard working hours: 9 AM to 6 PM (flexible depending on team policy).\n",
      "- Late arrival beyond grace periods should be informed to HR.\n",
      "- Attendance is tracked via system logs or biometric systems.\n",
      "**3. Work-from-Home (WFH) Policy**\n",
      "- WFH allowed upon prior approval from the reporting manager.\n",
      "- Employees must ensure productivity and availability during working hours.\n",
      "- Regular updates via Teams/Slack are mandatory.\n",
      "**4. Probation & Confirmation**\n",
      "- New hires undergo a 3–6 month probation period.\n",
      "- Upon satisfactory performance, HR will confirm employment via written notice.\n",
      "- Unsatisfactory performance may result in extension or termination.\n",
      "**5. Code of Conduct**\n",
      "\n",
      "- Regularly re-embed when documents are updated.\n",
      "**FAQs:**\n",
      "Q1: Why does RAG sometimes return irrelevant context?\n",
      "A1: Chunking or embedding mismatch can cause poor retrieval. Recheck embeddings and\n",
      "retriever logic.\n",
      "Q2: Can I use local LLMs like Ollama or Llama 3?\n",
      "A2: Yes, with LangChain or LlamaIndex integration using `OllamaLLM` or API endpoints.\n",
      "Q3: What’s the difference between RAG and fine-tuning?\n",
      "A3: RAG retrieves knowledge dynamically; fine-tuning embeds it permanently into the\n",
      "model.\n",
      "Q4: How to improve accuracy?\n",
      "A4: Use domain-specific embeddings, better retriever ranking, or hybrid (keyword +\n",
      "semantic) search.\n",
      "Section 2: HR Policies and Employee FAQs\n",
      "**1. Leave Policy**\n",
      "- Employees are entitled to annual leave, sick leave, and public holidays as per labor law.\n",
      "- All leave must be approved by reporting managers.\n",
      "- Emergency leave must be informed at the earliest.\n",
      "**2. Attendance & Working Hours**\n",
      "- Standard working hours: 9 AM to 6 PM (flexible depending on team policy).\n",
      "- Late arrival beyond grace periods should be informed to HR.\n",
      "- Attendance is tracked via system logs or biometric systems.\n",
      "**3. Work-from-Home (WFH) Policy**\n",
      "- WFH allowed upon prior approval from the reporting manager.\n",
      "- Employees must ensure productivity and availability during working hours.\n",
      "- Regular updates via Teams/Slack are mandatory.\n",
      "**4. Probation & Confirmation**\n",
      "- New hires undergo a 3–6 month probation period.\n",
      "- Upon satisfactory performance, HR will confirm employment via written notice.\n",
      "- Unsatisfactory performance may result in extension or termination.\n",
      "**5. Code of Conduct**\n",
      "\n",
      "- Regularly re-embed when documents are updated.\n",
      "**FAQs:**\n",
      "Q1: Why does RAG sometimes return irrelevant context?\n",
      "A1: Chunking or embedding mismatch can cause poor retrieval. Recheck embeddings and\n",
      "retriever logic.\n",
      "Q2: Can I use local LLMs like Ollama or Llama 3?\n",
      "A2: Yes, with LangChain or LlamaIndex integration using `OllamaLLM` or API endpoints.\n",
      "Q3: What’s the difference between RAG and fine-tuning?\n",
      "A3: RAG retrieves knowledge dynamically; fine-tuning embeds it permanently into the\n",
      "model.\n",
      "Q4: How to improve accuracy?\n",
      "A4: Use domain-specific embeddings, better retriever ranking, or hybrid (keyword +\n",
      "semantic) search.\n",
      "Section 2: HR Policies and Employee FAQs\n",
      "**1. Leave Policy**\n",
      "- Employees are entitled to annual leave, sick leave, and public holidays as per labor law.\n",
      "- All leave must be approved by reporting managers.\n",
      "- Emergency leave must be informed at the earliest.\n",
      "**2. Attendance & Working Hours**\n",
      "- Standard working hours: 9 AM to 6 PM (flexible depending on team policy).\n",
      "- Late arrival beyond grace periods should be informed to HR.\n",
      "- Attendance is tracked via system logs or biometric systems.\n",
      "**3. Work-from-Home (WFH) Policy**\n",
      "- WFH allowed upon prior approval from the reporting manager.\n",
      "- Employees must ensure productivity and availability during working hours.\n",
      "- Regular updates via Teams/Slack are mandatory.\n",
      "**4. Probation & Confirmation**\n",
      "- New hires undergo a 3–6 month probation period.\n",
      "- Upon satisfactory performance, HR will confirm employment via written notice.\n",
      "- Unsatisfactory performance may result in extension or termination.\n",
      "**5. Code of Conduct**\n",
      "Answer is\n",
      "\n",
      "\n",
      "Employees are entitled to annual leave, sick leave, and public holidays as per labor law. All leave must be approved by reporting managers. Emergency leave must be informed at the earliest.\n"
     ]
    }
   ],
   "source": [
    "answer=rag_simple(\"what is the Leave policy?\",rag_retriever,llm)\n",
    "print(\"Answer is\\n\\n\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a09e681e-708d-45da-9674-9f1580f3206c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: To control the bias-variance trade-off what is used?\n",
      "Retrieved 3 documents\n",
      "Context retrieved:\n",
      " 1-8\n",
      "2.4 Pruning a tree\n",
      "There is a trade-off between the model interpretability and its performance on the training set:\n",
      "• Small tree with fewer splits⇒ More interpretable (lower variance), but poorer fit in training set (higher\n",
      "bias);\n",
      "• Larger tree with many splits⇒ Less interpretable (higher variance), better fit in training set (lower\n",
      "bias).\n",
      "Yet, what often really matters is the model performance on the test set, meaning that we are interested in\n",
      "the bias-variance trade-off (illustrated in Figure 1.6)—where biasis the error introduced by approximating\n",
      "a functionf with a simpler functionˆf, while variancerefers to how the estimation would change if we used\n",
      "a different training set. This leads to the following trade-off:\n",
      "• More complex model ˆf ⇒ Low bias and high variance, since the model will capture many features of\n",
      "the data;\n",
      "• Simpler model ˆf ⇒ High bias and low variance.\n",
      "Figure 1.6: Bias-variance trade-off.\n",
      "To control the bias-variance trade-off (or, simply, the model complexity), CARTs usepruning. We first\n",
      "grow a large tree and then prune it back to get a subtree with the objective of getting low test error rates.\n",
      "For a regression tree, pruning can be easily implemented by introducing a cost complexityfunction, which\n",
      "measures the trade-off between the fit to the training data and the model complexity. For any value ofα,\n",
      "we want to find the sub-treeT ⊆ T0 of the original tree (T0) such that:\n",
      "min\n",
      "T⊆T0\n",
      "|T|X\n",
      "m=1\n",
      "X\n",
      "i∈Rm\n",
      "(yi − ¯yRm)2 + α|T|,\n",
      "where |T| is the number of leaves (terminal nodes) in the tree. Whenα = 0, T = T0 (original tree). As α\n",
      "increases, there is a price to be paid for having too many leaves and so we look for smaller sub-trees (similar\n",
      "to LASSO). To find the best value ofα, one can use cross-validation methods. In doing pruning of trees for\n",
      "classification problems,rpart uses the proportion of misclassified instances and number of terminal nodes.\n",
      "\n",
      "1-8\n",
      "2.4 Pruning a tree\n",
      "There is a trade-off between the model interpretability and its performance on the training set:\n",
      "• Small tree with fewer splits⇒ More interpretable (lower variance), but poorer fit in training set (higher\n",
      "bias);\n",
      "• Larger tree with many splits⇒ Less interpretable (higher variance), better fit in training set (lower\n",
      "bias).\n",
      "Yet, what often really matters is the model performance on the test set, meaning that we are interested in\n",
      "the bias-variance trade-off (illustrated in Figure 1.6)—where biasis the error introduced by approximating\n",
      "a functionf with a simpler functionˆf, while variancerefers to how the estimation would change if we used\n",
      "a different training set. This leads to the following trade-off:\n",
      "• More complex model ˆf ⇒ Low bias and high variance, since the model will capture many features of\n",
      "the data;\n",
      "• Simpler model ˆf ⇒ High bias and low variance.\n",
      "Figure 1.6: Bias-variance trade-off.\n",
      "To control the bias-variance trade-off (or, simply, the model complexity), CARTs usepruning. We first\n",
      "grow a large tree and then prune it back to get a subtree with the objective of getting low test error rates.\n",
      "For a regression tree, pruning can be easily implemented by introducing a cost complexityfunction, which\n",
      "measures the trade-off between the fit to the training data and the model complexity. For any value ofα,\n",
      "we want to find the sub-treeT ⊆ T0 of the original tree (T0) such that:\n",
      "min\n",
      "T⊆T0\n",
      "|T|X\n",
      "m=1\n",
      "X\n",
      "i∈Rm\n",
      "(yi − ¯yRm)2 + α|T|,\n",
      "where |T| is the number of leaves (terminal nodes) in the tree. Whenα = 0, T = T0 (original tree). As α\n",
      "increases, there is a price to be paid for having too many leaves and so we look for smaller sub-trees (similar\n",
      "to LASSO). To find the best value ofα, one can use cross-validation methods. In doing pruning of trees for\n",
      "classification problems,rpart uses the proportion of misclassified instances and number of terminal nodes.\n",
      "\n",
      "1-8\n",
      "2.4 Pruning a tree\n",
      "There is a trade-off between the model interpretability and its performance on the training set:\n",
      "• Small tree with fewer splits⇒ More interpretable (lower variance), but poorer fit in training set (higher\n",
      "bias);\n",
      "• Larger tree with many splits⇒ Less interpretable (higher variance), better fit in training set (lower\n",
      "bias).\n",
      "Yet, what often really matters is the model performance on the test set, meaning that we are interested in\n",
      "the bias-variance trade-off (illustrated in Figure 1.6)—where biasis the error introduced by approximating\n",
      "a functionf with a simpler functionˆf, while variancerefers to how the estimation would change if we used\n",
      "a different training set. This leads to the following trade-off:\n",
      "• More complex model ˆf ⇒ Low bias and high variance, since the model will capture many features of\n",
      "the data;\n",
      "• Simpler model ˆf ⇒ High bias and low variance.\n",
      "Figure 1.6: Bias-variance trade-off.\n",
      "To control the bias-variance trade-off (or, simply, the model complexity), CARTs usepruning. We first\n",
      "grow a large tree and then prune it back to get a subtree with the objective of getting low test error rates.\n",
      "For a regression tree, pruning can be easily implemented by introducing a cost complexityfunction, which\n",
      "measures the trade-off between the fit to the training data and the model complexity. For any value ofα,\n",
      "we want to find the sub-treeT ⊆ T0 of the original tree (T0) such that:\n",
      "min\n",
      "T⊆T0\n",
      "|T|X\n",
      "m=1\n",
      "X\n",
      "i∈Rm\n",
      "(yi − ¯yRm)2 + α|T|,\n",
      "where |T| is the number of leaves (terminal nodes) in the tree. Whenα = 0, T = T0 (original tree). As α\n",
      "increases, there is a price to be paid for having too many leaves and so we look for smaller sub-trees (similar\n",
      "to LASSO). To find the best value ofα, one can use cross-validation methods. In doing pruning of trees for\n",
      "classification problems,rpart uses the proportion of misclassified instances and number of terminal nodes.\n",
      "Answer is\n",
      "\n",
      "\n",
      "To control the bias-variance trade-off (or, simply, the model complexity), CARTs use pruning.\n"
     ]
    }
   ],
   "source": [
    "answer=rag_simple(\"To control the bias-variance trade-off what is used?\",rag_retriever,llm)\n",
    "print(\"Answer is\\n\\n\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9193f96c-b93e-4202-8cb7-06e36f634152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: give function approximation of random forests?\n",
      "Retrieved 3 documents\n",
      "Context retrieved:\n",
      " 1-9\n",
      "3 Random Forests\n",
      "Random Forests is a popular technique to solve classification and regression problems and was introduced\n",
      "by Breiman [2001]. It builds on a combination of tree predictors (ensemble method) that operates by\n",
      "constructing a multitude of trees during the training phase and asking each tree to output the mode of the\n",
      "classes (most popular class in classification) or mean predictions (in regression). Then we pick the majority\n",
      "(classification) or mean (regression) across trees to make predictions. From a mathematical standpoint, we\n",
      "can interpret the function approximation of random forests as follows:\n",
      "f(x) =\n",
      "BX\n",
      "t=1\n",
      "ft(x)\n",
      "B ,\n",
      "where B is the number of trees in the ensemble, and eachft(x) is a CART that trains on a subset of\n",
      "the data that is chosen randomly with replacement (this is known asbootstrapping). Bagging (bootstrap\n",
      "aggregation) uses the aboveB bootstrap samples and averages the output (for regression) or takes majority\n",
      "(for classification). One of the challenges with this approach is that, if we use the same algorithm, then the\n",
      "predictor variables chosen will be highly correlated. This can be improved by learning trees on randomly\n",
      "chosen subsets of input variables. Note that RF provide less interpretability but often better predictive power\n",
      "than CART. Naturally, the larger the number of trees the larger the time needed to build the ensemble (a\n",
      "similar concept applies to the node sizes; smaller the node size, the larger the time needed to build the\n",
      "ensemble).\n",
      "In a typical implementation, a random sample of m ≈ √p predictors (for classification) and m ≈ p/3\n",
      "predictors (for regression) are considered at each split of the tree and the split is made based only on one of\n",
      "this candidate variables. This helps decorrelate the trees chosen by the Random Forest method and reduces\n",
      "the variance.\n",
      "(Rough) algorithm for Random Forests.For a selected number of treesB:\n",
      "• Sample observations (with replacement) to create a subset of data;\n",
      "\n",
      "1-9\n",
      "3 Random Forests\n",
      "Random Forests is a popular technique to solve classification and regression problems and was introduced\n",
      "by Breiman [2001]. It builds on a combination of tree predictors (ensemble method) that operates by\n",
      "constructing a multitude of trees during the training phase and asking each tree to output the mode of the\n",
      "classes (most popular class in classification) or mean predictions (in regression). Then we pick the majority\n",
      "(classification) or mean (regression) across trees to make predictions. From a mathematical standpoint, we\n",
      "can interpret the function approximation of random forests as follows:\n",
      "f(x) =\n",
      "BX\n",
      "t=1\n",
      "ft(x)\n",
      "B ,\n",
      "where B is the number of trees in the ensemble, and eachft(x) is a CART that trains on a subset of\n",
      "the data that is chosen randomly with replacement (this is known asbootstrapping). Bagging (bootstrap\n",
      "aggregation) uses the aboveB bootstrap samples and averages the output (for regression) or takes majority\n",
      "(for classification). One of the challenges with this approach is that, if we use the same algorithm, then the\n",
      "predictor variables chosen will be highly correlated. This can be improved by learning trees on randomly\n",
      "chosen subsets of input variables. Note that RF provide less interpretability but often better predictive power\n",
      "than CART. Naturally, the larger the number of trees the larger the time needed to build the ensemble (a\n",
      "similar concept applies to the node sizes; smaller the node size, the larger the time needed to build the\n",
      "ensemble).\n",
      "In a typical implementation, a random sample of m ≈ √p predictors (for classification) and m ≈ p/3\n",
      "predictors (for regression) are considered at each split of the tree and the split is made based only on one of\n",
      "this candidate variables. This helps decorrelate the trees chosen by the Random Forest method and reduces\n",
      "the variance.\n",
      "(Rough) algorithm for Random Forests.For a selected number of treesB:\n",
      "• Sample observations (with replacement) to create a subset of data;\n",
      "\n",
      "1-9\n",
      "3 Random Forests\n",
      "Random Forests is a popular technique to solve classification and regression problems and was introduced\n",
      "by Breiman [2001]. It builds on a combination of tree predictors (ensemble method) that operates by\n",
      "constructing a multitude of trees during the training phase and asking each tree to output the mode of the\n",
      "classes (most popular class in classification) or mean predictions (in regression). Then we pick the majority\n",
      "(classification) or mean (regression) across trees to make predictions. From a mathematical standpoint, we\n",
      "can interpret the function approximation of random forests as follows:\n",
      "f(x) =\n",
      "BX\n",
      "t=1\n",
      "ft(x)\n",
      "B ,\n",
      "where B is the number of trees in the ensemble, and eachft(x) is a CART that trains on a subset of\n",
      "the data that is chosen randomly with replacement (this is known asbootstrapping). Bagging (bootstrap\n",
      "aggregation) uses the aboveB bootstrap samples and averages the output (for regression) or takes majority\n",
      "(for classification). One of the challenges with this approach is that, if we use the same algorithm, then the\n",
      "predictor variables chosen will be highly correlated. This can be improved by learning trees on randomly\n",
      "chosen subsets of input variables. Note that RF provide less interpretability but often better predictive power\n",
      "than CART. Naturally, the larger the number of trees the larger the time needed to build the ensemble (a\n",
      "similar concept applies to the node sizes; smaller the node size, the larger the time needed to build the\n",
      "ensemble).\n",
      "In a typical implementation, a random sample of m ≈ √p predictors (for classification) and m ≈ p/3\n",
      "predictors (for regression) are considered at each split of the tree and the split is made based only on one of\n",
      "this candidate variables. This helps decorrelate the trees chosen by the Random Forest method and reduces\n",
      "the variance.\n",
      "(Rough) algorithm for Random Forests.For a selected number of treesB:\n",
      "• Sample observations (with replacement) to create a subset of data;\n",
      "Answer is\n",
      "\n",
      "\n",
      "f(x) = \\(\\frac{1}{B} \\sum_{t=1}^{B} f_t(x)\\)\n"
     ]
    }
   ],
   "source": [
    "answer=rag_simple(\"give function approximation of random forests?\",rag_retriever,llm)\n",
    "print(\"Answer is\\n\\n\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "49b9babc-8429-45ca-b227-165b9cde0b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, Request\n",
    "from fastapi.responses import HTMLResponse, JSONResponse\n",
    "from fastapi.staticfiles import StaticFiles\n",
    "from fastapi.templating import Jinja2Templates\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from fastapi.exceptions import RequestValidationError\n",
    "\n",
    "# Import your LLM and LangChain schema\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "# -----------------------------\n",
    "# FastAPI App Setup\n",
    "# -----------------------------\n",
    "app = FastAPI(title=\"RAG Chatbot\")\n",
    "\n",
    "# CORS\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# Serve static files\n",
    "app.mount(\"/static\", StaticFiles(directory=\"static\"), name=\"static\")\n",
    "\n",
    "# HTML templates\n",
    "templates = Jinja2Templates(directory=\"templates\")\n",
    "\n",
    "# -----------------------------\n",
    "# LLM Setup\n",
    "# -----------------------------\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "    openai_api_key=\"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\",\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Exception Handling\n",
    "# -----------------------------\n",
    "@app.exception_handler(RequestValidationError)\n",
    "async def validation_exception_handler(request, exc):\n",
    "    return JSONResponse(status_code=400, content={\"error\": str(exc)})\n",
    "\n",
    "# -----------------------------\n",
    "# Serve Frontend\n",
    "# -----------------------------\n",
    "@app.get(\"/\", response_class=HTMLResponse)\n",
    "def serve_frontend(request: Request):\n",
    "    return templates.TemplateResponse(\"index.html\", {\"request\": request})\n",
    "\n",
    "# -----------------------------\n",
    "# RAG Query Function\n",
    "# -----------------------------\n",
    "def rag_simple(query, retriever, llm, top_k=3):\n",
    "    \"\"\"Retrieve top-k context and generate a concise answer using ChatOpenAI\"\"\"\n",
    "    results = retriever.retrieve(query, top_k=top_k)\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in results]) if results else \"\"\n",
    "\n",
    "    if not context:\n",
    "        return \"No relevant context found to answer the question.\"\n",
    "\n",
    "    prompt = f\"\"\"Use the following context to answer the question exactly as given in context for educational purpose. If the context has no answers say I don't know\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "    response = llm(\n",
    "        messages=[\n",
    "            SystemMessage(content=\"You are a helpful assistant that answers questions concisely using provided context.\"),\n",
    "            HumanMessage(content=prompt),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.content\n",
    "\n",
    "# -----------------------------\n",
    "# Query Endpoint\n",
    "# -----------------------------\n",
    "@app.post(\"/query\")\n",
    "async def query(request: Request):\n",
    "    try:\n",
    "        data = await request.json()\n",
    "        query_text = data.get(\"query\", \"\").strip()\n",
    "\n",
    "        if not query_text:\n",
    "            return {\"error\": \"Empty query\"}\n",
    "\n",
    "        # Call the RAG + LLM function\n",
    "        answer = rag_simple(query_text, rag_retriever, llm, top_k=3)\n",
    "\n",
    "        return {\"answer\": answer}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return {\"error\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1cb6a948-8a84-4f9e-9dbf-07a76fb7cc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55acdb92-b811-4ddb-8ed4-56da67dc4c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [20252]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:52759 - \"GET / HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52759 - \"GET /static/app.js HTTP/1.1\" 304 Not Modified\n",
      "\n",
      "Query: random forest\n",
      "Retrieved 3 documents\n",
      "INFO:     127.0.0.1:52765 - \"POST /query HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "import uvicorn\n",
    "\n",
    "# Run in notebook\n",
    "uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0458f65d-cfaf-4a05-bb6f-f9be63f143b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_c5c2928e',\n",
       "  'content': '- Regularly re-embed when documents are updated.\\n**FAQs:**\\nQ1: Why does RAG sometimes return irrelevant context?\\nA1: Chunking or embedding mismatch can cause poor retrieval. Recheck embeddings and\\nretriever logic.\\nQ2: Can I use local LLMs like Ollama or Llama 3?\\nA2: Yes, with LangChain or LlamaIndex integration using `OllamaLLM` or API endpoints.\\nQ3: What’s the difference between RAG and fine-tuning?\\nA3: RAG retrieves knowledge dynamically; fine-tuning embeds it permanently into the\\nmodel.\\nQ4: How to improve accuracy?\\nA4: Use domain-specific embeddings, better retriever ranking, or hybrid (keyword +\\nsemantic) search.\\nSection 2: HR Policies and Employee FAQs\\n**1. Leave Policy**\\n- Employees are entitled to annual leave, sick leave, and public holidays as per labor law.\\n- All leave must be approved by reporting managers.\\n- Emergency leave must be informed at the earliest.\\n**2. Attendance & Working Hours**\\n- Standard working hours: 9 AM to 6 PM (flexible depending on team policy).\\n- Late arrival beyond grace periods should be informed to HR.\\n- Attendance is tracked via system logs or biometric systems.\\n**3. Work-from-Home (WFH) Policy**\\n- WFH allowed upon prior approval from the reporting manager.\\n- Employees must ensure productivity and availability during working hours.\\n- Regular updates via Teams/Slack are mandatory.\\n**4. Probation & Confirmation**\\n- New hires undergo a 3–6 month probation period.\\n- Upon satisfactory performance, HR will confirm employment via written notice.\\n- Unsatisfactory performance may result in extension or termination.\\n**5. Code of Conduct**',\n",
       "  'metadata': {'page': 1,\n",
       "   'source': 'C:\\\\Users\\\\andia\\\\OneDrive\\\\Desktop\\\\EXAM\\\\RAG_and_HR_Policies_FAQs.pdf',\n",
       "   'file_type': 'pdf',\n",
       "   'source_file': 'RAG_and_HR_Policies_FAQs.pdf'},\n",
       "  'similarity_score': 0.37514281272888184,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_d09595d5',\n",
       "  'content': '- Regularly re-embed when documents are updated.\\n**FAQs:**\\nQ1: Why does RAG sometimes return irrelevant context?\\nA1: Chunking or embedding mismatch can cause poor retrieval. Recheck embeddings and\\nretriever logic.\\nQ2: Can I use local LLMs like Ollama or Llama 3?\\nA2: Yes, with LangChain or LlamaIndex integration using `OllamaLLM` or API endpoints.\\nQ3: What’s the difference between RAG and fine-tuning?\\nA3: RAG retrieves knowledge dynamically; fine-tuning embeds it permanently into the\\nmodel.\\nQ4: How to improve accuracy?\\nA4: Use domain-specific embeddings, better retriever ranking, or hybrid (keyword +\\nsemantic) search.\\nSection 2: HR Policies and Employee FAQs\\n**1. Leave Policy**\\n- Employees are entitled to annual leave, sick leave, and public holidays as per labor law.\\n- All leave must be approved by reporting managers.\\n- Emergency leave must be informed at the earliest.\\n**2. Attendance & Working Hours**\\n- Standard working hours: 9 AM to 6 PM (flexible depending on team policy).\\n- Late arrival beyond grace periods should be informed to HR.\\n- Attendance is tracked via system logs or biometric systems.\\n**3. Work-from-Home (WFH) Policy**\\n- WFH allowed upon prior approval from the reporting manager.\\n- Employees must ensure productivity and availability during working hours.\\n- Regular updates via Teams/Slack are mandatory.\\n**4. Probation & Confirmation**\\n- New hires undergo a 3–6 month probation period.\\n- Upon satisfactory performance, HR will confirm employment via written notice.\\n- Unsatisfactory performance may result in extension or termination.\\n**5. Code of Conduct**',\n",
       "  'metadata': {'source_file': 'RAG_and_HR_Policies_FAQs.pdf',\n",
       "   'page': 1,\n",
       "   'file_type': 'pdf',\n",
       "   'source': 'C:\\\\Users\\\\andia\\\\OneDrive\\\\Desktop\\\\EXAM\\\\RAG_and_HR_Policies_FAQs.pdf'},\n",
       "  'similarity_score': 0.37514281272888184,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_5a08fbb3',\n",
       "  'content': '- Regularly re-embed when documents are updated.\\n**FAQs:**\\nQ1: Why does RAG sometimes return irrelevant context?\\nA1: Chunking or embedding mismatch can cause poor retrieval. Recheck embeddings and\\nretriever logic.\\nQ2: Can I use local LLMs like Ollama or Llama 3?\\nA2: Yes, with LangChain or LlamaIndex integration using `OllamaLLM` or API endpoints.\\nQ3: What’s the difference between RAG and fine-tuning?\\nA3: RAG retrieves knowledge dynamically; fine-tuning embeds it permanently into the\\nmodel.\\nQ4: How to improve accuracy?\\nA4: Use domain-specific embeddings, better retriever ranking, or hybrid (keyword +\\nsemantic) search.\\nSection 2: HR Policies and Employee FAQs\\n**1. Leave Policy**\\n- Employees are entitled to annual leave, sick leave, and public holidays as per labor law.\\n- All leave must be approved by reporting managers.\\n- Emergency leave must be informed at the earliest.\\n**2. Attendance & Working Hours**\\n- Standard working hours: 9 AM to 6 PM (flexible depending on team policy).\\n- Late arrival beyond grace periods should be informed to HR.\\n- Attendance is tracked via system logs or biometric systems.\\n**3. Work-from-Home (WFH) Policy**\\n- WFH allowed upon prior approval from the reporting manager.\\n- Employees must ensure productivity and availability during working hours.\\n- Regular updates via Teams/Slack are mandatory.\\n**4. Probation & Confirmation**\\n- New hires undergo a 3–6 month probation period.\\n- Upon satisfactory performance, HR will confirm employment via written notice.\\n- Unsatisfactory performance may result in extension or termination.\\n**5. Code of Conduct**',\n",
       "  'metadata': {'file_type': 'pdf',\n",
       "   'source': 'C:\\\\Users\\\\andia\\\\OneDrive\\\\Desktop\\\\EXAM\\\\RAG_and_HR_Policies_FAQs.pdf',\n",
       "   'source_file': 'RAG_and_HR_Policies_FAQs.pdf',\n",
       "   'page': 1},\n",
       "  'similarity_score': 0.37514281272888184,\n",
       "  'rank': 3}]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329a21f4-79d2-466a-9e2c-dbe3ab57e87d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
